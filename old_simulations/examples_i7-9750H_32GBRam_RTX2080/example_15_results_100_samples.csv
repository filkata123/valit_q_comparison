Algorithm,Avg Time,Inconsistent?,Best Path,Worst Path
"Normal Q-learning (reward, discounting, stochastic approximation and termination goal)",0.12844637155532837,False,22,22
No-discounting Q-learning,0.12773961782455445,False,22,22
"No-discounting, no stochastic approximation Q-learning",0.12552870750427247,False,22,22
"cost-based Q-learning (No discounting, no stochastic approximation)",0.13038198947906493,False,22,22
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",0.1289367127418518,False,22,22
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",1.986750590801239,False,22,22
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",1.8937577438354491,False,0,0
Fully-random exploration Q-learning,3.7421562314033507,False,22,22
Fully-greedy exploration Q-learning,0.12904956579208374,False,22,22
One-episode random-exploration Q-learning,1.2850750017166137,False,22,22
Fully-greedy Q-learning with convergence,0.05573482990264893,False,22,22
Don't care Q-learning,1.3992280101776122,True,22,30
Stochastic Q-learning (converging),0.07879845142364501,True,22,130754
Value Iteration,0.022619781494140626,False,22,22
Random Action Value Iteration,0.10760064601898194,False,22,22
Stochastic Value Iteration,0.3311651849746704,True,22,30
