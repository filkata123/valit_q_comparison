Algorithm,Avg Time,Inconsistent?,Best Path,Worst Path
"Normal Q-learning (reward, discounting, stochastic approximation and termination goal)",0.13631608247756957,False,24,24
No-discounting Q-learning,0.1390072512626648,False,24,24
"No-discounting, no stochastic approximation Q-learning",0.13789122343063354,False,24,24
"cost-based Q-learning (No discounting, no stochastic approximation)",0.1438553524017334,False,24,24
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",0.1411317777633667,False,24,24
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",1.7045686006546021,False,24,24
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",1.664605541229248,False,0,0
Fully-random exploration Q-learning,4.481256487369538,False,24,24
Fully-greedy exploration Q-learning,0.12735909938812257,False,24,24
One-episode random-exploration Q-learning,1.1270278906822204,False,24,24
Fully-greedy Q-learning with convergence,0.052670695781707765,False,24,24
Don't care Q-learning,1.4255074167251587,True,24,36
Stochastic Q-learning (converging),0.08699900627136231,True,24,532560
Value Iteration,0.01933244228363037,False,24,24
Random Action Value Iteration,0.09480102062225342,False,24,24
Stochastic Value Iteration,0.27042816162109373,True,24,37
