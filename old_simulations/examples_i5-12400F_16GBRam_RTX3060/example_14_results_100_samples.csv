Algorithm,Avg Time,Shortest Path,Inconsistent?,Min Path,Max Path
"Normal Q-learning (reward, discounting, stochastic approximation and termination goal)",0.0989781928062439,24,False,24,24
No-discounting Q-learning,0.09958873510360718,24,False,24,24
"No-discounting, no stochastic approximation Q-learning",0.10110238552093506,24,False,24,24
"cost-based Q-learning (No discounting, no stochastic approximation)",0.10361600399017334,24,False,24,24
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",0.10330263137817383,24,False,24,24
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",1.2590796780586242,24,False,24,24
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",1.227609884738922,0,False,0,0
Fully-random exploration Q-learning,3.1969485020637514,24,False,24,24
Fully-greedy exploration Q-learning,0.08330831289291382,24,False,24,24
One-episode random-exploration Q-learning,0.7899859309196472,24,False,24,24
Fully-greedy Q-learning with convergence,0.03547399759292603,24,False,24,24
Don't care Q-learning,1.047563841342926,24,True,24,36
Stochastic Q-learning (converging),0.03824006795883179,25,True,1040,93
Value Iteration,0.011799893379211425,24,False,24,24
Random Action Value Iteration,0.06602414131164551,24,False,24,24
Stochastic Value Iteration,0.18658573150634766,28,True,24,39
