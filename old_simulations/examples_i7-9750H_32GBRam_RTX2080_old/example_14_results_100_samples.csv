Algorithm,Avg Time,Shortest Path,Inconsistent?,Min Path,Max Path
"Normal Q-learning (reward, discounting, stochastic approximation and termination goal)",0.14639828681945802,24,False,24,24
No-discounting Q-learning,0.1568734383583069,24,False,24,24
"No-discounting, no stochastic approximation Q-learning",0.15611493587493896,24,False,24,24
"cost-based Q-learning (No discounting, no stochastic approximation)",0.15343194723129272,24,False,24,24
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",0.1519273567199707,24,False,24,24
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",1.892429358959198,24,False,24,24
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",1.8389950180053711,0,False,0,0
Fully-random exploration Q-learning,4.827455594539642,24,False,24,24
Fully-greedy exploration Q-learning,0.137673282623291,24,False,24,24
One-episode random-exploration Q-learning,1.267988646030426,24,False,24,24
Fully-greedy Q-learning with convergence,0.06285925388336182,24,False,24,24
Don't care Q-learning,1.637410113811493,30,True,24,34
Stochastic Q-learning (converging),0.06045779943466187,707,True,1098,78
Value Iteration,0.019523308277130128,24,False,24,24
Random Action Value Iteration,0.10599584817886352,24,False,24,24
Stochastic Value Iteration,0.30110745191574095,25,True,24,43
