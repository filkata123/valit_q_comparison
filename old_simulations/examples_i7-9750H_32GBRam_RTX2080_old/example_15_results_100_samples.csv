Algorithm,Avg Time,Shortest Path,Inconsistent?,Min Path,Max Path
"Normal Q-learning (reward, discounting, stochastic approximation and termination goal)",0.14564368963241578,22,False,22,22
No-discounting Q-learning,0.13984434366226195,22,False,22,22
"No-discounting, no stochastic approximation Q-learning",0.14250799417495727,22,False,22,22
"cost-based Q-learning (No discounting, no stochastic approximation)",0.14048625230789186,22,False,22,22
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",0.1459028172492981,22,False,22,22
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",2.0226985096931456,22,False,22,22
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",1.8472480821609496,0,False,0,0
Fully-random exploration Q-learning,3.288249237537384,22,False,22,22
Fully-greedy exploration Q-learning,0.11439785957336426,22,False,22,22
One-episode random-exploration Q-learning,1.147661063671112,22,False,22,22
Fully-greedy Q-learning with convergence,0.05269655466079712,22,False,22,22
Don't care Q-learning,1.2497148704528809,22,True,22,32
Stochastic Q-learning (converging),0.06095830917358398,25,True,102,99
Value Iteration,0.01866896152496338,22,False,22,22
Random Action Value Iteration,0.0948142147064209,22,False,22,22
Stochastic Value Iteration,0.2973110580444336,22,True,22,33
