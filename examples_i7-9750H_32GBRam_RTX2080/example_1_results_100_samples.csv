Algorithm,Avg Time,Inconsistent?,Best Path,Worst Path
"Normal Q-learning (reward, discounting, stochastic approximation and termination goal)",0.15159267902374268,False,28,28
No-discounting Q-learning,0.1542413067817688,False,28,28
"No-discounting, no stochastic approximation Q-learning",0.15399981021881104,False,28,28
"cost-based Q-learning (No discounting, no stochastic approximation)",0.15425801753997803,False,28,28
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",0.15941426992416383,False,28,28
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",1.7860015797615052,False,28,28
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",1.6887385749816894,False,0,0
Fully-random exploration Q-learning,4.174082758426667,False,28,28
Fully-greedy exploration Q-learning,0.13841399908065796,False,28,28
One-episode random-exploration Q-learning,1.1306622886657716,False,28,28
Fully-greedy Q-learning with convergence,0.06432463645935059,False,28,28
Don't care Q-learning,1.709563992023468,True,28,40
Stochastic Q-learning (converging),0.09118707418441772,True,28,458
Value Iteration,0.017358906269073486,False,28,28
Random Action Value Iteration,0.08556136846542359,False,28,28
Stochastic Value Iteration,0.26024333000183103,True,28,39
