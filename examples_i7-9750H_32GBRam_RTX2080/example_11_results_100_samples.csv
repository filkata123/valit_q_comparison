Algorithm,Avg Time,Inconsistent?,Best Path,Worst Path
"Normal Q-learning (reward, discounting, stochastic approximation and termination goal)",0.14752426147460937,False,22,22
No-discounting Q-learning,0.14763761758804322,False,22,22
"No-discounting, no stochastic approximation Q-learning",0.14816844940185547,False,22,22
"cost-based Q-learning (No discounting, no stochastic approximation)",0.165702440738678,False,22,22
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",0.15279722929000855,False,22,22
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",2.025483069419861,False,22,22
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",1.8468020153045654,False,0,0
Fully-random exploration Q-learning,4.714988372325897,False,22,22
Fully-greedy exploration Q-learning,0.12370927095413208,False,22,22
One-episode random-exploration Q-learning,1.1409376311302184,False,22,22
Fully-greedy Q-learning with convergence,0.0562818717956543,False,22,22
Don't care Q-learning,1.574095573425293,True,22,42
Stochastic Q-learning (converging),0.07717374086380005,True,22,2798
Value Iteration,0.022214827537536622,False,22,22
Random Action Value Iteration,0.11275845289230346,False,22,22
Stochastic Value Iteration,0.31328621625900266,True,22,37
