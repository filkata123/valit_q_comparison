Algorithm,Avg Time,Shortest Path,Inconsistent?,Min Path,Max Path
"Normal Q-learning (reward, discounting, stochastic approximation and termination goal)",0.14790321826934816,22,False,22,22
No-discounting Q-learning,0.14612828969955444,22,False,22,22
"No-discounting, no stochastic approximation Q-learning",0.14236966371536255,22,False,22,22
"cost-based Q-learning (No discounting, no stochastic approximation)",0.14415266752243042,22,False,22,22
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",0.1537293338775635,22,False,22,22
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",1.8837475538253785,22,False,22,22
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",1.7356319808959961,0,False,0,0
Fully-random exploration Q-learning,4.733725440502167,22,False,22,22
Fully-greedy exploration Q-learning,0.12459913015365601,22,False,22,22
One-episode random-exploration Q-learning,1.1582108187675475,22,False,22,22
Fully-greedy Q-learning with convergence,0.05767557144165039,22,False,22,22
Don't care Q-learning,1.642010018825531,32,True,24,42
Stochastic Q-learning (converging),0.061023643016815184,25,True,1009,825
Value Iteration,0.02141639471054077,22,False,22,22
Random Action Value Iteration,0.10992888689041137,22,False,22,22
Stochastic Value Iteration,0.32451706886291504,27,True,22,33
