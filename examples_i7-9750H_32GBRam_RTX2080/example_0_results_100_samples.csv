Algorithm,Avg Time,Inconsistent?,Best Path,Worst Path
"Normal Q-learning (reward, discounting, stochastic approximation and termination goal)",0.1293890643119812,False,18,18
No-discounting Q-learning,0.13024818658828735,False,18,18
"No-discounting, no stochastic approximation Q-learning",0.12968558549880982,False,18,18
"cost-based Q-learning (No discounting, no stochastic approximation)",0.1348799419403076,False,18,18
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",0.12845431566238402,False,18,18
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",1.8065679240226746,False,18,18
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",1.7085401511192322,False,0,0
Fully-random exploration Q-learning,3.8501236915588377,False,18,18
Fully-greedy exploration Q-learning,0.11119551658630371,False,18,18
One-episode random-exploration Q-learning,1.1415782165527344,False,18,18
Fully-greedy Q-learning with convergence,0.057867658138275144,False,18,18
Don't care Q-learning,1.25365690946579,True,20,36
Stochastic Q-learning (converging),0.08195890665054321,True,18,2522
Value Iteration,0.02247689962387085,False,18,18
Random Action Value Iteration,0.10100179433822631,False,18,18
Stochastic Value Iteration,0.3500827670097351,True,18,32
