Algorithm,Avg Time,Inconsistent?,Best Path,Worst Path
"Normal Q-learning (reward, discounting, stochastic approximation and termination goal)",0.1687017822265625,False,31,31
No-discounting Q-learning,0.17092752933502198,False,31,31
"No-discounting, no stochastic approximation Q-learning",0.16242240190505983,False,31,31
"cost-based Q-learning (No discounting, no stochastic approximation)",0.16433630228042603,False,31,31
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",0.16288002967834472,False,31,31
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",1.8270314478874206,False,31,31
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",1.6833646345138549,False,0,0
Fully-random exploration Q-learning,4.629608154296875,False,31,31
Fully-greedy exploration Q-learning,0.145681893825531,False,31,31
One-episode random-exploration Q-learning,1.1392871952056884,False,31,31
Fully-greedy Q-learning with convergence,0.055578620433807374,False,31,31
Don't care Q-learning,1.6824583053588866,True,31,41
Stochastic Q-learning (converging),0.07969429016113282,True,31,230
Value Iteration,0.020836460590362548,False,31,31
Random Action Value Iteration,0.0839520001411438,False,31,31
Stochastic Value Iteration,0.25772494554519654,True,31,45
