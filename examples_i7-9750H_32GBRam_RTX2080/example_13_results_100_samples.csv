Algorithm,Avg Time,Inconsistent?,Best Path,Worst Path
"Normal Q-learning (reward, discounting, stochastic approximation and termination goal)",0.18259091138839723,False,33,33
No-discounting Q-learning,0.18481008291244508,False,33,33
"No-discounting, no stochastic approximation Q-learning",0.18171100854873656,False,33,33
"cost-based Q-learning (No discounting, no stochastic approximation)",0.18523193120956422,False,33,33
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",0.18446311950683594,False,33,33
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",1.8163431978225708,False,33,33
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",1.6999290633201598,False,0,0
Fully-random exploration Q-learning,6.7455111861228945,False,33,33
Fully-greedy exploration Q-learning,0.16414637327194215,False,33,33
One-episode random-exploration Q-learning,1.1459342122077942,False,33,33
Fully-greedy Q-learning with convergence,0.06322333812713624,False,33,33
Don't care Q-learning,2.294512026309967,True,33,51
Stochastic Q-learning (converging),0.09469210386276244,True,33,109580
Value Iteration,0.018021936416625976,False,33,33
Random Action Value Iteration,0.09346758842468261,False,33,33
Stochastic Value Iteration,0.27249826908111574,True,33,48
