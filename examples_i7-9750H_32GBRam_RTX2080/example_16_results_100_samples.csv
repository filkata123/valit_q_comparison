Algorithm,Avg Time,Inconsistent?,Best Path,Worst Path
"Normal Q-learning (reward, discounting, stochastic approximation and termination goal)",0.014763493537902832,False,5,5
No-discounting Q-learning,0.014614689350128173,False,5,5
"No-discounting, no stochastic approximation Q-learning",0.01399726390838623,False,5,5
"cost-based Q-learning (No discounting, no stochastic approximation)",0.013566815853118896,False,5,5
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",0.013515248298645019,False,5,5
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",1.710829906463623,False,5,5
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",1.5873894810676574,True,0,5
Fully-random exploration Q-learning,0.07395259857177734,False,5,5
Fully-greedy exploration Q-learning,0.01218839168548584,False,5,5
One-episode random-exploration Q-learning,1.2040319776535033,False,5,5
Fully-greedy Q-learning with convergence,0.0002430129051208496,False,5,5
Don't care Q-learning,0.19937264442443847,False,5,5
Stochastic Q-learning (converging),0.0002509164810180664,True,5,165
Value Iteration,0.0012554550170898438,False,5,5
Random Action Value Iteration,0.012823746204376221,False,5,5
Stochastic Value Iteration,0.015621931552886962,True,5,10
