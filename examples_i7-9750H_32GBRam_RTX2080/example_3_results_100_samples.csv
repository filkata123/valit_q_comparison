Algorithm,Avg Time,Inconsistent?,Best Path,Worst Path
"Normal Q-learning (reward, discounting, stochastic approximation and termination goal)",0.4014506506919861,False,91,91
No-discounting Q-learning,0.4153581929206848,False,91,91
"No-discounting, no stochastic approximation Q-learning",0.41283828735351563,False,91,91
"cost-based Q-learning (No discounting, no stochastic approximation)",0.4098024249076843,False,91,91
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",0.40305992603302004,False,91,91
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",1.7948241519927979,False,91,91
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",1.736987292766571,False,0,0
Fully-random exploration Q-learning,9.229499635696412,False,91,91
Fully-greedy exploration Q-learning,0.3306681489944458,False,91,91
One-episode random-exploration Q-learning,1.0932803273200988,False,91,91
Fully-greedy Q-learning with convergence,0.08705323457717895,False,91,91
Don't care Q-learning,6.978800673484802,True,91,99
Stochastic Q-learning (converging),0.12617448806762696,True,93,206
Value Iteration,0.01680835485458374,False,91,91
Random Action Value Iteration,0.07846218824386597,False,91,91
Stochastic Value Iteration,0.14513097047805787,True,93,120
