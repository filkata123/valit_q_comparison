Algorithm,Goal reached,Loops encountered,Avg Time,Var Time,STD Time,Avg Iterations,Var Iterations,STD iterations,Avg action count,Var action count,STD action count,Shortest Path,Longest Path
"Normal Q-learning (reward, alpha = 0.3, gamma = 0.6 and termination goal, initial values = 0)",False,True,0.2911456274986267,0.0004949819177350661,0.022248189088891396,999.0,0.0,0.0,83218.13,6480.8731000000025,80.50387009330672,5,28
"Normal Q-learning (reward, alpha = 0.6, gamma = 0.6 and termination goal, initial values = 0)",True,False,0.19340113878250123,0.00021678717074912013,0.014723694195042226,999.0,0.0,0.0,55798.92,9612.413599999998,98.04291713326363,28,28
"Normal Q-learning (reward, alpha = 0.9, gamma = 0.6 and termination goal, initial values = 0)",True,False,0.16765250205993654,0.0003457562859004156,0.01859452300814451,999.0,0.0,0.0,46469.09,11551.021900000002,107.47568050494029,28,28
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.6 and termination goal, initial values = 0)",True,False,0.16643403053283692,0.0004409665028659674,0.020999202434044188,999.0,0.0,0.0,45147.02,11281.6996,106.21534540733745,28,28
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.9 and termination goal, initial values = 0)",True,False,0.1644873332977295,0.00033855915019817074,0.018399976907544496,999.0,0.0,0.0,45129.83,14072.161100000001,118.62614003667152,28,28
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.9 and termination goal, initial values = -1e4)",False,True,1.5914053058624267,0.007384820505871537,0.08593497836080216,999.0,0.0,0.0,500000.0,0.0,0.0,12,12
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = -1e4)",True,False,0.16729405164718628,0.0004013664070474704,0.020034131052967342,999.0,0.0,0.0,45176.46,11617.648399999996,107.78519564392874,28,28
"Normal Q-learning (reward, alpha = 0.2, gamma = 0.999 and termination goal, initial values = 0)",False,True,0.344015805721283,0.001291987192932601,0.035944223359708316,999.0,0.0,0.0,93633.76,8604.602400000002,92.76099611366838,2,38
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.5 and termination goal, initial values = 0)",True,False,0.16599647998809813,0.00041137962352934216,0.02028249549560759,999.0,0.0,0.0,45123.91,10608.601900000001,102.99806745759845,28,28
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = 0)",True,False,0.15265556812286377,2.6446627609880126e-05,0.005142628472860948,999.0,0.0,0.0,45155.33,13508.641099999999,116.22667981147873,28,28
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = +1e4)",True,False,0.1509729242324829,1.3395685937462075e-05,0.003660011740071618,999.0,0.0,0.0,45167.09,16342.061900000004,127.83607432958821,28,28
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = +1e7)",True,False,0.15176658630371093,4.0025414527917746e-05,0.0063265641961429385,999.0,0.0,0.0,45179.15,13460.4875,116.01934106001464,28,28
No-discounting Q-learning,True,False,0.15421368598937987,1.7255689577586964e-05,0.004153996819640931,999.0,0.0,0.0,45159.59,10812.241900000005,103.98193064181875,28,28
"No-discounting, no stochastic approximation Q-learning",True,False,0.15345377206802369,2.7742966638987814e-05,0.0052671592570367395,999.0,0.0,0.0,44981.82,13811.807599999998,117.52364698221375,28,28
"cost-based  Q-learning (reward, alpha = 0.999, gamma = 0.9 and termination goal, initial values = +1e4)",False,True,1.5731947064399718,0.004494051017330065,0.06703768356178534,999.0,0.0,0.0,500000.0,0.0,0.0,12,12
"cost-based  Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = +1e4)",True,False,0.15443278789520265,2.227749097621654e-05,0.004719903704125387,999.0,0.0,0.0,45179.73,12441.1171,111.53975569275737,28,28
"cost-based Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = 0)",True,False,0.15463286638259888,1.5988451911397304e-05,0.003998556228365096,999.0,0.0,0.0,45160.63,12610.233099999998,112.29529420238408,28,28
"cost-based Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = -1e4)",True,False,0.15468846321105956,2.3688529650280548e-05,0.004867086361498072,999.0,0.0,0.0,45170.72,13849.041599999999,117.68195103753166,28,28
"cost-based Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = -1e7)",True,False,0.15564717054367067,4.042535848427064e-05,0.006358093934841687,999.0,0.0,0.0,45183.07,12246.3451,110.66320571897418,28,28
cost-based no-discounting Q-learning,True,False,0.15668911457061768,2.0263899052201853e-05,0.004501544074226293,999.0,0.0,0.0,45165.15,12121.767500000002,110.09889872292094,28,28
"cost-based Q-learning (No discounting, no stochastic approximation)",True,False,0.15573694944381714,1.6856775948662064e-05,0.00410570042120246,999.0,0.0,0.0,44975.94,15102.656399999996,122.89286553742653,28,28
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",True,False,0.1550646209716797,2.1427011532432514e-05,0.004628932007756489,999.0,0.0,0.0,45003.55,14309.4275,119.62201929410823,28,28
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",True,False,1.8963060593605041,0.014513070580476435,0.12047020619421399,999.0,0.0,0.0,500000.0,0.0,0.0,28,28
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",False,True,1.7191406893730163,0.0007782077625882437,0.027896375438186297,999.0,0.0,0.0,500000.0,0.0,0.0,2,14
"Fully-random exploration Q-learning(No discounting, no stochastic approximation) w/ term action & term goal",True,False,4.284620857238769,0.04113851890180058,0.2028263269445083,999.0,0.0,0.0,1439262.94,816238803.0764,28569.893298302675,28,28
"Fully-greedy exploration Q-learning(No discounting, no stochastic approximation) w/ term action & term goal",True,False,0.14197906494140625,1.9548960473821353e-05,0.004421420639774206,999.0,0.0,0.0,40915.0,0.0,0.0,28,28
"One-episode random-exploration Q-learning(No discounting, no stochastic approximation) w/ term action only",True,False,1.1423112440109253,0.0006136656428097695,0.024772275688958605,0.0,0.0,0.0,400000.0,0.0,0.0,28,28
"Fully-greedy Q-learning with convergence (No discounting, no stochastic approximation) w/ term action & term goal (best case)",True,False,0.06930150747299195,8.096441964761428e-06,0.0028454247424174526,221.0,0.0,0.0,19909.0,0.0,0.0,28,28
Don't care Q-learning,True,False,1.7944808220863342,0.03404524106212545,0.18451352541785507,14999.0,0.0,0.0,531625.93,1919420028.6051002,43811.18611273952,28,40
"Stochastic-problem Q-learning (converging, no discounting, no stochastic approximation)",True,True,0.0942608904838562,0.00015220623258421144,0.012337189006585392,185.03,77.2891,8.791421955520052,21008.39,111079.79789999999,333.2863602069547,28,14955
"Stochastic-problem Q-learning (converging, no stochastic approximation, gamma = 0.6)",True,True,0.09200562715530396,0.00014493923334413805,0.012039071116333604,186.04,112.9984,10.630070554798777,20782.43,171945.6651,414.66331535355283,28,2868
"Stochastic-problem Q-learning (converging, no stochastic approximation, gamma = 0.6)",True,True,0.09642135620117187,0.0001986874409538814,0.014095653264530928,189.49,112.36989999999997,10.600466970846142,20995.41,149093.5019,386.1262771425949,28,172
"Stochastic-problem Q-learning (converging, no discounting, alpha = 0.2)",True,True,0.4480390524864197,0.0015826903923021915,0.039783041516482764,999.0,0.0,0.0,98494.15,38785.9275,196.9414316491073,28,530
"Stochastic-problem Q-learning (converging, alpha = 0.7, gamma = 0.7)",True,True,0.1452652931213379,0.0002481168201552464,0.01575172435497925,366.66,107.32440000000003,10.359749031709216,33525.69,141822.1939,376.592875530061,28,261
"Stochastic-problem Q-learning (converging, alpha = 0.9, gamma = 0.9)",True,True,0.12439588546752929,0.00028426733598134886,0.016860229416628614,319.94,75.9564,8.715296896836046,26863.96,97204.25839999999,311.77597469978343,28,71
Value Iteration,True,False,0.019156723022460936,2.0196028388318153e-05,0.004493999153128331,27.0,0.0,0.0,28890.0,0.0,0.0,28,28
Discounted Value Iteration - gamma = 0.8,True,False,0.02286846876144409,2.3215388422039494e-05,0.004818234990329913,27.0,0.0,0.0,28890.0,0.0,0.0,28,28
Discounted Value Iteration - gamma = 0.6,True,False,0.022871673107147217,3.086682600311974e-05,0.005555792113022206,27.0,0.0,0.0,28890.0,0.0,0.0,28,28
Discounted Value Iteration - gamma = 0.5,True,False,0.02309459924697876,3.65586581731975e-05,0.006046375622899846,27.0,0.0,0.0,28890.0,0.0,0.0,28,28
Stochastic Value Iteration,True,True,0.2963150668144226,0.0012691297638269304,0.0356248475621571,98.0,0.0,0.0,280672.0,0.0,0.0,28,47
Discounted Stochastic Value Iteration - gamma = 0.8,True,True,0.24974801301956176,0.0010807898558517707,0.03287536852799936,82.0,0.0,0.0,234848.0,0.0,0.0,28,39
Discounted Stochastic Value Iteration - gamma = 0.6,True,True,0.20869647741317748,0.0008631824818331264,0.029379967355889394,69.0,0.0,0.0,197616.0,0.0,0.0,28,41
Random Action Value Iteration,True,False,0.09261804819107056,0.0002289589347064691,0.015131389054097747,150.0,100.0,10.0,45149.0,8940100.0,2990.0,28,28
Random Action Discounted Value Iteration - gamma = 0.8,True,False,0.09983669757843018,0.00016173702067296747,0.012717587061741212,150.0,100.0,10.0,45149.0,8940100.0,2990.0,28,28
Random Action Discounted Value Iteration - gamma = 0.6,True,False,0.1030285120010376,0.00019078237698124664,0.013812399392619901,150.5,24.75,4.9749371855331,45298.5,2212674.75,1487.5062184743967,28,28
Random Action Discounted Value Iteration - gamma = 0.5,True,False,0.0957834267616272,3.238388792362343e-05,0.005690684310662772,150.5,24.75,4.9749371855331,45298.5,2212674.75,1487.5062184743967,28,28
Random Action Discounted Value Iteration - gamma = 0.5,True,False,0.09633706331253052,2.8649646912134592e-05,0.005352536493302459,150.0,0.0,0.0,45149.0,0.0,0.0,28,28
Q-factor Value Iteration,True,False,0.023921236991882325,9.070061163151878e-06,0.003011654223703624,27.0,0.0,0.0,28890.0,0.0,0.0,28,28
Q-factor Stochastic Value Iteration,True,True,0.29520230770111083,5.028454650366711e-05,0.007091159743206122,98.0,0.0,0.0,280672.0,0.0,0.0,28,41
