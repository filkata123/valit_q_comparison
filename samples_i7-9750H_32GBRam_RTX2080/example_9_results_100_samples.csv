Algorithm,Goal reached,Loops encountered,Avg Time,Var Time,STD Time,Avg Iterations,Var Iterations,STD iterations,Avg action count,Var action count,STD action count,Shortest Path,Longest Path
"Normal Q-learning (reward, alpha = 0.3, gamma = 0.6 and termination goal, initial values = 0)",True,False,0.5563195371627807,0.001266767495903446,0.035591677340404256,999.0,0.0,0.0,165514.32,19264.1376,138.79530827805382,73,73
"Normal Q-learning (reward, alpha = 0.6, gamma = 0.6 and termination goal, initial values = 0)",True,False,0.40378143787384035,0.0006087843201822807,0.024673555077902348,999.0,0.0,0.0,121097.46,18791.0284,137.080372045016,73,73
"Normal Q-learning (reward, alpha = 0.9, gamma = 0.6 and termination goal, initial values = 0)",True,False,0.3512723898887634,0.0008855431132823186,0.029758076437873444,999.0,0.0,0.0,106045.1,26322.43,162.24188731643872,73,73
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.6 and termination goal, initial values = 0)",True,False,0.3550226879119873,0.00046451252339088563,0.021552552595710924,999.0,0.0,0.0,103286.04,23965.998399999997,154.8095552606492,73,73
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.9 and termination goal, initial values = 0)",True,False,0.3540023708343506,0.0002936663551069159,0.01713669615494527,999.0,0.0,0.0,103368.36,22147.470399999995,148.8202620613201,73,73
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.9 and termination goal, initial values = -1e4)",False,True,1.6691528677940368,0.007473180683877416,0.08644756031188744,999.0,0.0,0.0,500000.0,0.0,0.0,19,19
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = -1e4)",True,False,0.3488420748710632,0.0004607268971156997,0.021464549776682943,999.0,0.0,0.0,103352.86,32018.5004,178.93714091825655,73,73
"Normal Q-learning (reward, alpha = 0.2, gamma = 0.999 and termination goal, initial values = 0)",True,False,0.6197516798973084,0.001338907570953296,0.036591085949357886,999.0,0.0,0.0,184776.3,26428.509999999995,162.56847787932318,73,73
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.5 and termination goal, initial values = 0)",False,True,1.4498174858093262,0.005720548262845658,0.07563430612391217,999.0,0.0,0.0,435549.38,8992371.7356,2998.7283530856876,19,19
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = 0)",True,False,0.34858466625213624,0.0004754021163260177,0.021803717947313887,999.0,0.0,0.0,103256.1,32700.11,180.83171735069044,73,73
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = +1e4)",True,False,0.3503423762321472,0.0004360098383679712,0.020880848602678272,999.0,0.0,0.0,103383.36,29602.79040000001,172.0546145850207,73,73
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = +1e7)",True,False,0.3516057777404785,0.0007310616143484821,0.02703815108968219,999.0,0.0,0.0,103344.02,26350.1996,162.32744561533642,73,73
No-discounting Q-learning,True,False,0.3571325397491455,0.0004870484544338978,0.02206917430340106,999.0,0.0,0.0,103194.14,24857.460399999996,157.6624888805197,73,73
"No-discounting, no stochastic approximation Q-learning",True,False,0.3498358964920044,0.0003914386579668872,0.01978480876750865,999.0,0.0,0.0,102395.36,35998.31040000001,189.73220707091352,73,73
"cost-based  Q-learning (reward, alpha = 0.999, gamma = 0.9 and termination goal, initial values = +1e4)",False,True,1.72749107837677,0.006316661653570033,0.07947742857925157,999.0,0.0,0.0,500000.0,0.0,0.0,19,20
"cost-based  Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = +1e4)",True,False,0.35650202989578245,0.0004952522633526485,0.02225426393643808,999.0,0.0,0.0,103389.58,28944.5036,170.13084258887335,73,73
"cost-based Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = 0)",True,False,0.34213297605514525,0.00045184191608574906,0.02125657347941453,999.0,0.0,0.0,103252.94,25514.7564,159.7333916249198,73,73
"cost-based Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = -1e4)",True,False,0.3444122505187988,0.00040086857183709983,0.020021702520942115,999.0,0.0,0.0,103395.88,22954.705600000005,151.50810407367655,73,73
"cost-based Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = -1e7)",True,False,0.3559937596321106,0.00045162622151494246,0.02125149927687321,999.0,0.0,0.0,103379.38,27673.815599999987,166.35448776633586,73,73
cost-based no-discounting Q-learning,True,False,0.3575832748413086,0.0004624021555058789,0.021503538208998977,999.0,0.0,0.0,103183.12,25867.385599999994,160.83340946457608,73,73
"cost-based Q-learning (No discounting, no stochastic approximation)",True,False,0.3585409188270569,0.000411683484746726,0.020289984838504093,999.0,0.0,0.0,102415.34,27406.484400000005,165.54903926027478,73,73
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",True,False,0.3555754661560059,0.0004840388229558812,0.02200088232221338,999.0,0.0,0.0,102391.08,30591.953600000004,174.9055562296407,73,73
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",True,False,1.6468274593353271,0.006977133037181602,0.0835292346258578,999.0,0.0,0.0,500000.0,0.0,0.0,73,73
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",False,True,1.716343343257904,0.005626335470383737,0.07500890260751544,999.0,0.0,0.0,500000.0,0.0,0.0,2,16
"Fully-random exploration Q-learning(No discounting, no stochastic approximation) w/ term action & term goal",True,False,8.878984293937684,0.09206896750853982,0.3034286860343626,999.0,0.0,0.0,2954434.58,50197550.26360001,7085.022954345314,73,73
"Fully-greedy exploration Q-learning(No discounting, no stochastic approximation) w/ term action & term goal",True,False,0.31031481027603147,0.0003138128342747848,0.01771476317298046,999.0,0.0,0.0,92530.0,0.0,0.0,73,73
"One-episode random-exploration Q-learning(No discounting, no stochastic approximation) w/ term action only",True,False,1.1236089062690735,0.00308971494750387,0.05558520439383011,0.0,0.0,0.0,400000.0,0.0,0.0,73,73
"Fully-greedy Q-learning with convergence (No discounting, no stochastic approximation) w/ term action & term goal (best case)",True,False,0.11137068271636963,7.281281477105494e-05,0.008533042527203,169.0,0.0,0.0,32770.0,0.0,0.0,73,73
Don't care Q-learning,True,False,6.39983743429184,0.29689145126427363,0.5448774644489104,14999.0,0.0,0.0,2093664.29,33224644218.6859,182276.28539852874,73,91
"Stochastic-problem Q-learning (converging, no discounting, no stochastic approximation)",False,True,0.7836878538131714,0.002994292604888074,0.05472012979597247,999.0,0.0,0.0,192658.7,21492382.97,4635.987809518054,115,100002
"Stochastic-problem Q-learning (converging, no stochastic approximation, gamma = 0.6)",False,True,0.26211938619613645,0.009135541283236416,0.0955800255452802,58.57,476.92510000000004,21.83861488281709,26018.1,43861333.10999999,6622.788922349858,499,100002
"Stochastic-problem Q-learning (converging, no stochastic approximation, gamma = 0.6)",False,True,0.7965763068199158,0.002698577529588073,0.05194783469585689,999.0,0.0,0.0,194245.71,21620281.765899997,4649.7614740866,94,100002
"Stochastic-problem Q-learning (converging, no discounting, alpha = 0.2)",True,True,0.8644051766395568,0.001958790461392363,0.044258224788081627,999.0,0.0,0.0,212998.26,389775.07239999995,624.3196876600961,77,280
"Stochastic-problem Q-learning (converging, alpha = 0.7, gamma = 0.7)",False,True,0.5518830561637879,0.006204483262617596,0.078768542341582,953.32,39650.357599999996,199.12397545248035,134887.14,503733042.58039993,22443.997918828987,79,100002
"Stochastic-problem Q-learning (converging, alpha = 0.9, gamma = 0.9)",False,True,0.627094144821167,0.0018343686299323054,0.04282952988222385,999.0,0.0,0.0,155223.95,3393706.8275000006,1842.2016250942786,81,100002
Value Iteration,True,False,0.014170246124267578,3.617555249547877e-07,0.000601461158309319,31.0,0.0,0.0,20522.0,0.0,0.0,73,73
Discounted Value Iteration - gamma = 0.8,True,False,0.01881016492843628,6.213928237883692e-06,0.002492775208053003,31.0,0.0,0.0,20522.0,0.0,0.0,73,73
Discounted Value Iteration - gamma = 0.6,True,False,0.0181805157661438,4.132903571752421e-06,0.002032954394902262,31.0,0.0,0.0,20522.0,0.0,0.0,73,73
Discounted Value Iteration - gamma = 0.5,False,True,0.020329694747924804,6.481338499133926e-06,0.0025458473047561053,32.0,0.0,0.0,21184.0,0.0,0.0,19,19
Stochastic Value Iteration,True,True,0.21546146631240845,0.00030247922947739306,0.01739193001013381,124.0,0.0,0.0,185256.0,0.0,0.0,76,99
Discounted Stochastic Value Iteration - gamma = 0.8,True,True,0.16801119089126587,0.00014746428809245913,0.012143487476522514,99.0,0.0,0.0,147906.0,0.0,0.0,75,93
Discounted Stochastic Value Iteration - gamma = 0.6,True,True,0.1318810200691223,0.00010535583805914825,0.010264299199611644,77.0,0.0,0.0,115038.0,0.0,0.0,74,95
Random Action Value Iteration,True,False,0.10145568370819091,0.00014578754632109392,0.012074251377252916,232.0,576.0,24.0,50095.0,26625600.0,5160.0,73,73
Random Action Discounted Value Iteration - gamma = 0.8,True,False,0.12097671508789062,0.00025670034191680314,0.01602187073711441,228.0,616.0,24.819347291981714,49235.0,28474600.0,5336.159667776068,73,73
Random Action Discounted Value Iteration - gamma = 0.6,True,False,0.1169729208946228,0.0004210106841963978,0.020518544884966815,221.0,709.0,26.627053911388696,47730.0,32773525.0,5724.81659094857,73,73
Random Action Discounted Value Iteration - gamma = 0.5,False,True,0.10544058799743652,0.00015451603902679378,0.012430448062189623,197.0,341.0,18.466185312619388,42570.0,15762725.0,3970.2298422131685,2,13
Random Action Discounted Value Iteration - gamma = 0.5,False,True,0.10629110097885132,0.00016181782992782132,0.012720763732096485,199.5,424.75,20.60946384552495,43107.5,19634068.75,4431.034726787864,2,18
Q-factor Value Iteration,True,False,0.019840047359466553,6.473632255045913e-06,0.0025443333616186996,31.0,0.0,0.0,20522.0,0.0,0.0,73,73
Q-factor Stochastic Value Iteration,True,True,0.2286010789871216,0.0002250412289767837,0.015001374236275278,124.0,0.0,0.0,185256.0,0.0,0.0,76,97
