Algorithm,Goal reached,Loops encountered,Avg Time,Var Time,STD Time,Avg Iterations,Var Iterations,STD iterations,Avg action count,Var action count,STD action count,Shortest Path,Longest Path
"Normal Q-learning (reward, alpha = 0.3, gamma = 0.6 and termination goal, initial values = 0)",False,True,0.7297602701187134,0.0013852203478770433,0.037218548438608445,999.0,0.0,0.0,217933.5,20250.37,142.30379474912115,5,66
"Normal Q-learning (reward, alpha = 0.6, gamma = 0.6 and termination goal, initial values = 0)",True,False,0.4709241724014282,0.0006483953460304065,0.025463608268083426,999.0,0.0,0.0,141213.58,18743.543599999997,136.90706190697395,64,64
"Normal Q-learning (reward, alpha = 0.9, gamma = 0.6 and termination goal, initial values = 0)",True,False,0.3886441802978516,0.0005399155719211648,0.023236083403215025,999.0,0.0,0.0,115313.44,22602.486399999998,150.34123319967813,64,64
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.6 and termination goal, initial values = 0)",True,False,0.37565247535705565,0.0004635512550326894,0.021530240477818388,999.0,0.0,0.0,110684.12,27414.1656,165.5722368031549,64,64
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.9 and termination goal, initial values = 0)",True,False,0.3722822189331055,0.0004619216182481978,0.021492361858302073,999.0,0.0,0.0,110674.31,31211.033900000002,176.66644814451894,64,64
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.9 and termination goal, initial values = -1e4)",False,True,1.5326056504249572,0.004072771888242521,0.06381827236961622,999.0,0.0,0.0,500000.0,0.0,0.0,4,4
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = -1e4)",True,False,0.3664849066734314,0.0004481094936442048,0.021168596874715263,999.0,0.0,0.0,110684.14,28348.5204,168.37018857268052,64,64
"Normal Q-learning (reward, alpha = 0.2, gamma = 0.999 and termination goal, initial values = 0)",False,True,0.8524091506004333,0.0020179378615738357,0.04492146326171751,999.0,0.0,0.0,250052.33,32293.661100000005,179.7043713992512,2,68
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.5 and termination goal, initial values = 0)",False,True,1.4597429752349853,0.004653333326580195,0.0682153452426959,999.0,0.0,0.0,473724.32,4007544.5376000004,2001.8852458620102,4,4
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = 0)",True,False,0.3624640417098999,0.00031343450089455014,0.017704081475596246,999.0,0.0,0.0,110700.71,32215.565899999998,179.48695189344545,64,64
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = +1e4)",True,False,0.36859606266021727,0.0004027933217853615,0.020069711552121557,999.0,0.0,0.0,110671.76,32357.32240000001,179.8814120469372,64,64
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = +1e7)",True,False,0.37184293508529664,0.00044055784016074426,0.020989469744630146,999.0,0.0,0.0,110695.87,24310.233099999998,155.91739190994699,64,64
No-discounting Q-learning,True,False,0.37472420930862427,0.00046225992448100327,0.021500230800644983,999.0,0.0,0.0,110421.94,31629.3764,177.84649673243496,64,64
"No-discounting, no stochastic approximation Q-learning",True,False,0.3770233368873596,0.000442525516234008,0.021036290458015833,999.0,0.0,0.0,110272.67,46252.70110000001,215.06441151431824,64,64
"cost-based  Q-learning (reward, alpha = 0.999, gamma = 0.9 and termination goal, initial values = +1e4)",False,True,1.539851474761963,0.0038923153515679587,0.06238842321751655,999.0,0.0,0.0,500000.0,0.0,0.0,4,4
"cost-based  Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = +1e4)",True,False,0.3769460415840149,0.0004755395794567164,0.021806870005957216,999.0,0.0,0.0,110684.14,29032.040400000005,170.38791154304346,64,64
"cost-based Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = 0)",True,False,0.3722021245956421,0.00037538762592705555,0.019374922604414594,999.0,0.0,0.0,110672.78,23141.091599999996,152.12196291134293,64,64
"cost-based Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = -1e4)",True,False,0.3795122003555298,0.0004977974241619677,0.022311374322572953,999.0,0.0,0.0,110667.76,28022.482399999994,167.39917084621416,64,64
"cost-based Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = -1e7)",True,False,0.38180467367172244,0.0005258861312286797,0.022932207290810008,999.0,0.0,0.0,110684.47,34505.3291,185.75610111110754,64,64
cost-based no-discounting Q-learning,True,False,0.3888420820236206,0.0009076882809034712,0.030127865521863164,999.0,0.0,0.0,110378.39,23336.837900000006,152.7639941216516,64,64
"cost-based Q-learning (No discounting, no stochastic approximation)",True,False,0.37920365571975706,0.0004549482332278046,0.021329515541329218,999.0,0.0,0.0,110312.32,38233.617600000005,195.53418524646784,64,64
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",True,False,0.3789674353599548,0.00046290822194652604,0.02151530204172198,999.0,0.0,0.0,110253.72,30434.501600000003,174.45486980878465,64,64
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",True,False,1.6958976483345032,0.0043747346821866075,0.06614177713205631,999.0,0.0,0.0,500000.0,0.0,0.0,64,64
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",False,True,1.7008979058265685,0.0045004221377006335,0.06708518567985508,999.0,0.0,0.0,500000.0,0.0,0.0,2,15
"Fully-random exploration Q-learning(No discounting, no stochastic approximation) w/ term action & term goal",True,False,8.320693378448487,0.050225766140602535,0.22411105760448888,999.0,0.0,0.0,2902847.87,133321958.91309999,11546.512846444159,64,64
"Fully-greedy exploration Q-learning(No discounting, no stochastic approximation) w/ term action & term goal",True,False,0.33962594509124755,0.0003548773377024417,0.01883818828078862,999.0,0.0,0.0,100159.0,0.0,0.0,64,64
"One-episode random-exploration Q-learning(No discounting, no stochastic approximation) w/ term action only",True,False,1.1089601278305055,0.0020428616086957166,0.045198026601785575,0.0,0.0,0.0,400000.0,0.0,0.0,64,64
"Fully-greedy Q-learning with convergence (No discounting, no stochastic approximation) w/ term action & term goal (best case)",True,False,0.17431366443634033,5.723960714760778e-05,0.007565686165022165,247.0,0.0,0.0,52783.0,0.0,0.0,64,64
Don't care Q-learning,True,False,5.879072315692902,0.2883043692051904,0.5369398189789899,14999.0,0.0,0.0,1930038.49,27845515407.9699,166869.75582162844,68,94
"Stochastic-problem Q-learning (converging, no discounting, no stochastic approximation)",False,True,0.7441265511512757,0.002301262252696523,0.04797147332213722,999.0,0.0,0.0,183575.95,7937818.087500001,2817.413368233352,92,100002
"Stochastic-problem Q-learning (converging, no stochastic approximation, gamma = 0.6)",False,True,0.2869019675254822,0.008981725921708239,0.09477196801643532,131.0,2373.28,48.71632170022692,51477.72,170184256.16160002,13045.46879807698,438,100002
"Stochastic-problem Q-learning (converging, no stochastic approximation, gamma = 0.6)",True,True,0.7565889883041382,0.0013455387347762326,0.03668158577237675,999.0,0.0,0.0,188671.6,5474815.360000001,2339.832335873663,89,12006
"Stochastic-problem Q-learning (converging, no discounting, alpha = 0.2)",True,True,1.1482696771621703,0.0019573829124914254,0.04424232037869878,999.0,0.0,0.0,285282.22,951810.7916000001,975.6079087420316,74,9781
"Stochastic-problem Q-learning (converging, alpha = 0.7, gamma = 0.7)",True,True,0.6380303049087525,0.0009205316732400434,0.03034026488414436,999.0,0.0,0.0,158633.38,2066396.1156000001,1437.4964749869823,65,1309
"Stochastic-problem Q-learning (converging, alpha = 0.9, gamma = 0.9)",True,True,0.6837566804885864,0.001661384478391915,0.04076008437665353,999.0,0.0,0.0,164760.13,3151881.7531,1775.353979661521,81,3883
Value Iteration,True,False,0.031409993171691894,1.5682175307824765e-05,0.003960072639210646,43.0,0.0,0.0,50912.0,0.0,0.0,64,64
Discounted Value Iteration - gamma = 0.8,True,False,0.03471107482910156,1.1130461213042508e-05,0.0033362345860329587,43.0,0.0,0.0,50912.0,0.0,0.0,64,64
Discounted Value Iteration - gamma = 0.6,True,False,0.034470009803771975,7.171173486426596e-06,0.0026779046821025195,43.0,0.0,0.0,50912.0,0.0,0.0,64,64
Discounted Value Iteration - gamma = 0.5,False,True,0.03433902263641357,3.2047634186938007e-06,0.0017901853028929157,43.0,0.0,0.0,50912.0,0.0,0.0,13,13
Stochastic Value Iteration,True,True,0.39399033546447754,0.0007220181903222965,0.02687039616980547,132.0,0.0,0.0,405768.0,0.0,0.0,65,87
Discounted Stochastic Value Iteration - gamma = 0.8,True,True,0.3170173168182373,0.0003298752009254713,0.018162466818289615,109.0,0.0,0.0,335066.0,0.0,0.0,66,84
Discounted Stochastic Value Iteration - gamma = 0.6,True,True,0.2612294363975525,0.0003929152247338322,0.019822089313032372,87.0,0.0,0.0,267438.0,0.0,0.0,65,83
Random Action Value Iteration,True,False,0.16038105249404908,0.0002979275736332682,0.01726057860076736,253.5,462.75,21.511624764298954,86275.5,53179692.75,7292.4407950973455,64,64
Random Action Discounted Value Iteration - gamma = 0.8,True,False,0.1852616000175476,0.0004189813068006232,0.020469032874091124,242.0,536.0,23.15167380558045,82377.0,61597656.0,7848.417420091773,64,64
Random Action Discounted Value Iteration - gamma = 0.6,True,False,0.16755000352859498,0.0002599069076079274,0.016121628565623495,236.0,554.0,23.53720459187964,80343.0,63666234.0,7979.112356647198,64,64
Random Action Discounted Value Iteration - gamma = 0.5,False,True,0.15299697160720827,0.00022211655514717564,0.014903575247140387,208.5,352.75,18.78163997099295,71020.5,40538382.75,6366.975950166609,2,10
Random Action Discounted Value Iteration - gamma = 0.5,False,True,0.15878061294555665,0.0004136020090649254,0.020337207504102558,212.5,518.75,22.776083947860748,72376.5,59615268.75,7721.092458324793,2,12
Q-factor Value Iteration,True,False,0.043070068359375,1.7173732115816162e-05,0.00414412018597629,43.0,0.0,0.0,50912.0,0.0,0.0,64,64
Q-factor Stochastic Value Iteration,True,True,0.4281580781936645,0.0006261901700316002,0.02502379207937119,132.0,0.0,0.0,405768.0,0.0,0.0,66,85
