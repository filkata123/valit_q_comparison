Algorithm,Goal reached,Loops encountered,Avg Time,Var Time,STD Time,Avg Iterations,Var Iterations,STD iterations,Avg action count,Var action count,STD action count,Avg convergence action,Var convergence actio ,STD convergence action,Convergence rate,Shortest Path,Longest Path
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0",True,False,0.018902046680450438,1.6048434024759217e-05,0.004006049678269007,999.0,0.0,0.0,5094.0,0.0,0.0,0.0,0.0,0.0,0.0,6,6
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.25",True,False,0.0257578444480896,4.321127662007597e-05,0.00657352847564198,951.61,12737.7579,112.86167595778471,6892.81,635828.4739,797.3885338403105,5000.0,0.0,0.0,0.15,6,6
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.5",True,False,0.021325030326843263,7.418645876239224e-05,0.008613156144085176,530.57,35694.5051,188.92989466995422,6095.51,4498513.4099,2120.9699219696636,5927.835051546392,3778297.3748538634,1943.7842922644127,0.97,6,6
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.75",True,False,0.016966049671173097,2.07995203298367e-05,0.004560649112772951,234.35,86.1875,9.283722313813572,5014.09,137.9619,11.745718368835515,5000.0,0.0,0.0,1.0,6,6
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.9",True,False,0.017857842445373535,6.578912027157459e-06,0.0025649389909230703,148.57,68.8251,8.296089440212178,5025.43,472.04509999999993,21.726598905489094,5000.0,0.0,0.0,1.0,6,6
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",True,False,0.015801870822906496,3.218693890786994e-05,0.005673353409392891,109.79,65.34590000000001,8.083681092175768,5036.15,1327.3474999999996,36.43278056915228,5000.0,0.0,0.0,1.0,6,6
"Fully-random (deterministic with pi) exploration Q-learning (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",True,False,0.01747509479522705,1.9604838561258474e-05,0.004427735150306359,109.66,77.3844,8.796840341850022,5033.92,786.2536000000001,28.040213979212073,5000.0,0.0,0.0,1.0,6,6
Model-free Dijkstra,True,False,0.00010262012481689454,6.925654965698414e-07,0.0008322052009990333,11.0,0.0,0.0,119.0,0.0,0.0,28.0,0.0,0.0,1.0,6,6
Model-free Value Iteration,True,False,0.0002073359489440918,3.191236369900707e-07,0.0005649102910994547,6.0,0.0,0.0,319.0,0.0,0.0,228.0,0.0,0.0,1.0,6,6
Model-free Synchronous Value Iteration,True,False,0.00028258323669433594,2.0350962031443483e-07,0.0004511204055620127,7.0,0.0,0.0,357.0,0.0,0.0,266.0,0.0,0.0,1.0,6,6

