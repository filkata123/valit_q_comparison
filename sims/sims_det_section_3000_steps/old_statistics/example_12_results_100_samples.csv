Algorithm,Goal reached,Loops encountered,Avg Time,Var Time,STD Time,Avg Iterations,Var Iterations,STD iterations,Avg action count,Var action count,STD action count,Avg convergence action,Var convergence actio ,STD convergence action,Convergence rate,Shortest Path,Longest Path
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0",True,False,0.5237324285507202,0.0009837262118162246,0.031364409954855274,999.0,0.0,0.0,126594.0,0.0,0.0,0.0,0.0,0.0,0.0,91,91
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.25",True,False,0.6907254004478455,0.0022196323693796046,0.0471129745333449,999.0,0.0,0.0,164905.06,219126.83640000003,468.1098550554133,0.0,0.0,0.0,0.0,91,91
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.5",True,False,0.9306613397598267,0.0019169839526707397,0.043783375300115224,999.0,0.0,0.0,242716.08,1018351.9936,1009.1342792710988,0.0,0.0,0.0,0.0,91,91
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.75",True,False,1.8054428505897522,0.009216174599588449,0.09600090936854946,999.0,0.0,0.0,486608.12,8429504.945600001,2903.360974043703,0.0,0.0,0.0,0.0,91,91
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.9",True,False,1.1754591155052185,0.08327298911585176,0.28857059641594074,231.98,4274.5196,65.37981033927828,348265.68,6700909200.0576,81859.08135361403,347500.0,6707750000.0,81900.85469639496,1.0,91,91
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",True,False,6.450845053195954,4.309095234981426,2.0758360327784624,620.43,40178.6451,200.44611520306398,1853405.84,359114888618.8544,599261.9532548803,1804739.5833333333,318689255099.82635,564525.6903807181,0.96,91,91
"Fully-random (deterministic with pi) exploration Q-learning (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",True,False,6.673543903827667,1.8650019168360175,1.3656507301781147,596.1,14348.329999999998,119.78451485897499,1781948.5,127918882777.63,357657.4936690548,1779950.0,128395247500.0,358322.8258149347,1.0,91,91
Model-free Dijkstra,True,False,0.0028760409355163574,1.6480625458251554e-05,0.004059633660596921,306.0,0.0,0.0,3006.0,0.0,0.0,867.0,0.0,0.0,1.0,91,91
Model-free Value Iteration,True,False,0.04162791728973389,7.525228271563265e-05,0.008674807358992627,68.0,0.0,0.0,61435.0,0.0,0.0,59296.0,0.0,0.0,1.0,91,91
Model-free Synchronous Value Iteration,True,False,0.05770157814025879,7.701428414397922e-05,0.008775778264289682,103.0,0.0,0.0,91955.0,0.0,0.0,89816.0,0.0,0.0,1.0,91,91