Algorithm,Goal reached,Loops encountered,Avg Time,Var Time,STD Time,Avg Iterations,Var Iterations,STD iterations,Avg action count,Var action count,STD action count,Avg convergence action,Var convergence actio ,STD convergence action,Convergence rate,Shortest Path,Longest Path
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0",True,False,0.20681862831115722,0.00013991306418574822,0.011828485287041118,615.0,0.0,0.0,50036.0,0.0,0.0,50000.0,0.0,0.0,1.0,39,39
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.25",True,False,0.25539162635803225,0.0003268258380640874,0.018078325090120695,609.88,2434.9055999999996,49.344762640020875,60388.06,6675343.796399999,2583.6686700116948,60151.51515151515,2249770.4315886144,1499.923475244192,0.99,39,39
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.5",True,False,0.4089388656616211,0.003959152180390993,0.0629217941606165,796.4,28890.6,169.97235069269354,96359.04,186923955.39840004,13672.01358243913,90866.66666666667,130248888.88888891,11412.66353174792,0.75,39,41
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.75",False,True,0.8324352979660035,0.017448262791336332,0.13209187254080523,902.19,26695.813899999997,163.38853662359546,203517.98,927023277.5595999,30447.056960560243,168382.35294117648,855471453.2871971,29248.443604527012,0.34,16,39
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.9",False,True,1.1011416149139404,0.08174327568878298,0.2859078097722813,463.49,19860.289899999996,140.92654079342185,290192.24,5597739898.742401,74818.04527480253,289850.0,5587727500.0,74751.10367078202,1.0,2,39
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",False,True,0.6430505776405334,0.0017992818113895,0.0424179420928161,85.68,39.67759999999999,6.299015796138313,173631.66,99730907.44440001,9986.53630867079,172250.0,103187500.0,10158.124826955021,1.0,2,39
"Fully-random (deterministic with pi) exploration Q-learning (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",False,True,0.6566604733467102,0.002583349535622545,0.0508266616612044,88.42,46.543600000000005,6.822287006568986,175745.92,115336461.8336,10739.481450870893,174550.0,114547500.0,10702.686578611932,1.0,2,39
Model-free Dijkstra,True,False,0.004380478858947754,1.6761009974516124e-06,0.0012946431931044214,400.0,0.0,0.0,5782.0,0.0,0.0,1518.0,0.0,0.0,1.0,39,39
Model-free Value Iteration,True,False,0.03168769359588623,3.868274501585347e-05,0.006219545402668387,26.0,0.0,0.0,43784.0,0.0,0.0,39520.0,0.0,0.0,1.0,39,39
Model-free Synchronous Value Iteration,True,False,0.038662521839141845,5.343686218299695e-05,0.007310052132714031,39.0,0.0,0.0,63544.0,0.0,0.0,59280.0,0.0,0.0,1.0,39,39