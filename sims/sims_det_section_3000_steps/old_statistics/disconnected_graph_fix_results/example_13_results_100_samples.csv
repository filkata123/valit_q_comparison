Algorithm,Goal reached,Loops encountered,Avg Time,Var Time,STD Time,Avg Iterations,Var Iterations,STD iterations,Avg action count,Var action count,STD action count,Avg convergence action,Var convergence actio ,STD convergence action,Convergence rate,Shortest Path,Longest Path
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0",True,False,0.19076948404312133,0.00021672036760070915,0.014721425460895733,999.0,0.0,0.0,47576.0,0.0,0.0,0.0,0.0,0.0,0.0,33,33
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.25",True,False,0.25032915592193605,0.0005928447301575716,0.024348403030949928,999.0,0.0,0.0,63543.78,72184.47159999999,268.67167993668403,0.0,0.0,0.0,0.0,33,33
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.5",True,False,0.41338172912597654,0.002121745520295827,0.046062408971913604,999.0,0.0,0.0,96410.66,299863.28440000006,547.597739586277,0.0,0.0,0.0,0.0,33,33
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.75",True,False,0.8719766116142273,0.0072858194221902236,0.08535701155845501,999.0,0.0,0.0,214623.76,4127387.0624,2031.5971703071455,0.0,0.0,0.0,0.0,33,33
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.9",True,False,0.642467691898346,0.016563558729162306,0.12869949001127512,212.37,1954.2530999999997,44.206934976313384,156775.6,716331996.3200002,26764.37924406244,156450.0,716147500.0,26760.932345492,1.0,33,33
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",True,False,0.9459454226493835,0.05819687010724245,0.24124027463763684,108.52,671.5496000000002,25.914274058904297,252428.62,3747932355.2555995,61220.35899319441,251100.0,3722290000.0,61010.572854219296,1.0,33,35
"Fully-random (deterministic with pi) exploration Q-learning (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",True,False,1.1406276607513428,0.10197563146564302,0.3193362357541703,118.55,992.5874999999999,31.50535668739524,278245.82,5477933093.9276,74013.0602929483,277100.0,5530090000.0,74364.57489961198,1.0,33,33
Model-free Dijkstra,True,False,0.002927875518798828,1.200511979050134e-05,0.0034648405144394943,280.0,0.0,0.0,3874.0,0.0,0.0,964.0,0.0,0.0,1.0,33,33
Model-free Value Iteration,True,False,0.01894077777862549,4.370819306334395e-05,0.006611217214957012,24.0,0.0,0.0,27870.0,0.0,0.0,24960.0,0.0,0.0,1.0,33,33
Model-free Synchronous Value Iteration,True,False,0.029358525276184082,8.033885515621933e-05,0.008963194472743484,37.0,0.0,0.0,41390.0,0.0,0.0,38480.0,0.0,0.0,1.0,33,33
