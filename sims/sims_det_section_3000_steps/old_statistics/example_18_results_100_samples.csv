Algorithm,Goal reached,Loops encountered,Avg Time,Var Time,STD Time,Avg Iterations,Var Iterations,STD iterations,Avg action count,Var action count,STD action count,Avg convergence action,Var convergence actio ,STD convergence action,Convergence rate,Shortest Path,Longest Path
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0",True,False,0.2063097310066223,0.00029783226127944425,0.017257817396166997,999.0,0.0,0.0,48008.0,0.0,0.0,0.0,0.0,0.0,0.0,32,32
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.25",True,False,0.2624934577941895,0.0010055481316618626,0.03171037892649444,999.0,0.0,0.0,61807.74,76013.85239999999,275.7060978650998,0.0,0.0,0.0,0.0,32,32
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.5",True,False,0.36456453800201416,0.0003913290991232543,0.01978203981199245,999.0,0.0,0.0,89121.36,381692.4303999999,617.8126175467768,0.0,0.0,0.0,0.0,32,32
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.75",True,False,0.6964871335029602,0.0006923170321156874,0.026311918062271466,999.0,0.0,0.0,180451.86,4507752.7204,2123.146890914522,0.0,0.0,0.0,0.0,32,32
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.9",True,False,0.9766425824165345,0.08594542079414041,0.29316449442956155,485.66,27842.664399999994,166.86121298851927,261966.04,6485812201.118399,80534.54042284217,259141.41414141413,5911131517.192123,76883.88333839625,0.99,32,32
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",True,False,0.6894457459449768,0.0426614999510825,0.20654660479195125,101.54,827.1084,28.759492346006386,186536.15,3100859482.2875,55685.36147218136,185350.0,3106127500.0,55732.64303798987,1.0,32,32
"Fully-random (deterministic with pi) exploration Q-learning (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",True,False,0.7110318684577942,0.03509024341156271,0.18732389973402408,99.82,652.4476,25.5430538503132,180921.18,2167062041.6675997,46551.71362761633,179950.0,2165747500.0,46537.592331361535,1.0,32,32
Model-free Dijkstra,True,False,0.00305757999420166,7.978042756121796e-07,0.0008931989003644035,292.0,0.0,0.0,3986.0,0.0,0.0,1019.0,0.0,0.0,1.0,32,32
Model-free Value Iteration,True,False,0.019065742492675782,1.723658988621537e-05,0.004151697229593624,21.0,0.0,0.0,25647.0,0.0,0.0,22680.0,0.0,0.0,1.0,32,32
Model-free Synchronous Value Iteration,True,False,0.0259928035736084,1.5473332976034724e-05,0.003933615763649867,34.0,0.0,0.0,39687.0,0.0,0.0,36720.0,0.0,0.0,1.0,32,32
