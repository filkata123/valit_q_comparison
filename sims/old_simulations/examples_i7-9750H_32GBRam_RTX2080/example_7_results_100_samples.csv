Algorithm,Avg Time,Inconsistent?,Best Path,Worst Path
"Normal Q-learning (reward, discounting, stochastic approximation and termination goal)",0.1486750888824463,False,29,29
No-discounting Q-learning,0.16255510807037354,False,29,29
"No-discounting, no stochastic approximation Q-learning",0.15295594215393066,False,29,29
"cost-based Q-learning (No discounting, no stochastic approximation)",0.15687445163726807,False,29,29
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",0.15049690246582031,False,29,29
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",2.018264064788818,False,29,29
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",1.8951069927215576,False,0,0
Fully-random exploration Q-learning,6.548232927322387,False,29,29
Fully-greedy exploration Q-learning,0.13878321170806884,False,29,29
One-episode random-exploration Q-learning,1.2828703117370606,False,29,29
Fully-greedy Q-learning with convergence,0.04548061847686768,False,29,29
Don't care Q-learning,2.0483870840072633,True,29,47
Stochastic Q-learning (converging),0.0616215968132019,True,29,1891
Value Iteration,0.017123878002166748,False,29,29
Random Action Value Iteration,0.09525545120239258,False,29,29
Stochastic Value Iteration,0.3316468119621277,True,29,41
