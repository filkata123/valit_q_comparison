Algorithm,Goal reached,Loops encountered,Avg Time,Var Time,STD Time,Avg Iterations,Var Iterations,STD iterations,Avg action count,Var action count,STD action count,Shortest Path,Longest Path
"Normal Q-learning (reward, alpha = 0.3, gamma = 0.6 and termination goal, initial values = 0)",True,False,0.288227858543396,6.555462358348905e-05,0.008096580981098691,999.0,0.0,0.0,78510.82,42092.66760000001,205.16497654326872,18,18
"Normal Q-learning (reward, alpha = 0.6, gamma = 0.6 and termination goal, initial values = 0)",True,False,0.18132274150848388,4.076601785584443e-05,0.006384827159433874,999.0,0.0,0.0,49067.67,19429.2611,139.38888442053047,18,18
"Normal Q-learning (reward, alpha = 0.9, gamma = 0.6 and termination goal, initial values = 0)",True,False,0.14340917587280275,4.7355573421873484e-05,0.006881538594084428,999.0,0.0,0.0,38642.96,26161.0984,161.74392847955684,18,18
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.6 and termination goal, initial values = 0)",True,False,0.138486168384552,3.959733383350681e-05,0.0062926412446211175,999.0,0.0,0.0,37334.64,23204.6704,152.33079268486722,18,18
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.9 and termination goal, initial values = 0)",True,False,0.13750399112701417,2.0760009855871434e-05,0.004556315381519527,999.0,0.0,0.0,37364.68,27911.4576,167.06722479289587,18,18
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.9 and termination goal, initial values = -1e4)",False,True,1.5803507804870605,0.006061097438603154,0.07785305028451457,999.0,0.0,0.0,500000.0,0.0,0.0,11,11
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = -1e4)",True,False,0.13084466695785524,0.00010554771079534362,0.010273641554743071,999.0,0.0,0.0,37407.42,25698.623600000003,160.3079024876815,18,18
"Normal Q-learning (reward, alpha = 0.2, gamma = 0.999 and termination goal, initial values = 0)",True,False,0.3197795414924622,0.0006460853641668734,0.02541820930291655,999.0,0.0,0.0,90904.65,36760.2475,191.72962082057117,18,18
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.5 and termination goal, initial values = 0)",True,False,0.12638132333755492,1.8382009756913933e-05,0.0042874246065574065,999.0,0.0,0.0,37353.39,26159.9179,161.7402791514841,18,18
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = 0)",True,False,0.1268461012840271,3.8838302748325754e-05,0.006232038410369897,999.0,0.0,0.0,37389.65,35965.9475,189.6469021629407,18,18
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = +1e4)",True,False,0.1249741244316101,1.4827424822050261e-05,0.0038506395341618596,999.0,0.0,0.0,37379.41,34380.8019,185.4206080779588,18,18
"Normal Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = +1e7)",True,False,0.1255717968940735,3.126970334084831e-05,0.0055919319864290475,999.0,0.0,0.0,37376.05,28882.3475,169.94807295171074,18,18
No-discounting Q-learning,True,False,0.12806288480758668,3.5927305929197926e-05,0.005993939099556979,999.0,0.0,0.0,37414.57,22312.965099999998,149.3752492884949,18,18
"No-discounting, no stochastic approximation Q-learning",True,False,0.12612841606140138,3.342631996893033e-05,0.005781549962504028,999.0,0.0,0.0,36862.73,36225.397099999995,190.32970629935832,18,18
"cost-based  Q-learning (reward, alpha = 0.999, gamma = 0.9 and termination goal, initial values = +1e4)",False,True,1.5261319017410278,0.0008193462451584084,0.02862422479576361,999.0,0.0,0.0,500000.0,0.0,0.0,11,11
"cost-based  Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = +1e4)",True,False,0.12903554916381835,3.349509718859735e-05,0.005787494897500762,999.0,0.0,0.0,37406.99,24847.549899999998,157.6310562674754,18,18
"cost-based Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = 0)",True,False,0.12876226425170897,2.8889137709802526e-05,0.005374861645642846,999.0,0.0,0.0,37387.74,27706.772399999998,166.4535142314514,18,18
"cost-based Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = -1e4)",True,False,0.13006002426147462,5.813060859177313e-05,0.007624343158054543,999.0,0.0,0.0,37405.81,23245.3339,152.4642053073442,18,18
"cost-based Q-learning (reward, alpha = 0.999, gamma = 0.999 and termination goal, initial values = -1e7)",True,False,0.12929075956344604,3.603364968668643e-05,0.006002803485596246,999.0,0.0,0.0,37394.63,28403.853100000004,168.53442704682033,18,18
cost-based no-discounting Q-learning,True,False,0.13154289722442628,3.8418763661525194e-05,0.006198287155458772,999.0,0.0,0.0,37339.62,24239.4156,155.69012685459538,18,18
"cost-based Q-learning (No discounting, no stochastic approximation)",True,False,0.1292031478881836,3.4484462617092505e-05,0.005872347283420192,999.0,0.0,0.0,36861.71,38953.365900000004,197.36607079232238,18,18
"cost-based Q-learning (No discounting, no stochastic approximation) w/ term action & term goal",True,False,0.12982667684555055,6.166153060505053e-05,0.007852485632272786,999.0,0.0,0.0,36857.11,38002.15790000001,194.94142171431912,18,18
"cost-based Q-learning (No discounting, no stochastic approximation, no term goal) w/ term action",True,False,1.810106747150421,0.0006462055684976972,0.0254205737247942,999.0,0.0,0.0,500000.0,0.0,0.0,18,18
"cost-based Q-learning (No discounting, no stochastic approximation, no termination at all)",False,True,1.7131019091606141,0.0006475916137750288,0.025447821395456014,999.0,0.0,0.0,500000.0,0.0,0.0,2,15
"Fully-random exploration Q-learning(No discounting, no stochastic approximation) w/ term action & term goal",True,False,3.948530607223511,0.056309610001193375,0.23729646015310338,999.0,0.0,0.0,1303577.02,856045386.4995999,29258.253305684535,18,18
"Fully-greedy exploration Q-learning(No discounting, no stochastic approximation) w/ term action & term goal",True,False,0.11905464172363281,0.00016865860027510281,0.012986862603227263,999.0,0.0,0.0,32129.0,0.0,0.0,18,18
"One-episode random-exploration Q-learning(No discounting, no stochastic approximation) w/ term action only",True,False,1.1863316869735718,0.006075346822900224,0.0779445111787881,0.0,0.0,0.0,400000.0,0.0,0.0,18,18
"Fully-greedy Q-learning with convergence (No discounting, no stochastic approximation) w/ term action & term goal (best case)",True,False,0.060044457912445066,2.425145149720151e-05,0.0049245762759045075,112.0,0.0,0.0,17050.0,0.0,0.0,18,18
Don't care Q-learning,True,False,1.2781029343605042,0.022155105196739414,0.14884591091709376,14999.0,0.0,0.0,385613.84,1524892962.0744,39049.877875281505,18,30
"Stochastic-problem Q-learning (converging, no discounting, no stochastic approximation)",True,True,0.08034220695495606,6.757113677795133e-05,0.008220166468992665,101.53,36.8891,6.0736397654125,18425.0,105692.16,325.10330665805293,18,6034
"Stochastic-problem Q-learning (converging, no stochastic approximation, gamma = 0.6)",True,True,0.08195955514907836,0.00018662096347417785,0.013660928353306661,99.31,33.4539,5.7839346469336945,18243.44,109845.02639999999,331.4287651969877,18,3616
"Stochastic-problem Q-learning (converging, no stochastic approximation, gamma = 0.6)",True,True,0.08085056066513062,0.00010557855774329142,0.01027514271157785,99.16,35.27440000000001,5.939225538738196,18248.2,93020.22000000002,304.9921638337615,18,11105
"Stochastic-problem Q-learning (converging, no discounting, alpha = 0.2)",True,True,0.40079148769378664,0.0016829719881368643,0.04102404158706044,740.21,101.54589999999999,10.076998561079582,87550.81,149634.3939,386.82605121682275,18,799
"Stochastic-problem Q-learning (converging, alpha = 0.7, gamma = 0.7)",True,True,0.12593619108200074,0.0002668849672557542,0.016336614314347825,218.52,75.4296,8.685021588919627,27905.74,130603.3924,361.3909135548374,18,651
"Stochastic-problem Q-learning (converging, alpha = 0.9, gamma = 0.9)",True,True,0.08862148761749268,1.9372282148901834e-05,0.004401395477448241,170.0,77.14,8.782938005018593,21391.46,99934.86839999998,316.12476714107675,18,1474
Value Iteration,True,False,0.024290454387664796,1.9999119499942706e-05,0.0044720375110169535,28.0,0.0,0.0,42560.0,0.0,0.0,18,18
Discounted Value Iteration - gamma = 0.8,True,False,0.028552913665771486,3.2111136105186235e-05,0.005666668872025807,28.0,0.0,0.0,42560.0,0.0,0.0,18,18
Discounted Value Iteration - gamma = 0.6,True,False,0.028177754878997804,2.949044956978355e-05,0.005430510986066003,28.0,0.0,0.0,42560.0,0.0,0.0,18,18
Discounted Value Iteration - gamma = 0.5,True,False,0.027371912002563475,1.4520475972722126e-05,0.0038105742313622663,28.0,0.0,0.0,42560.0,0.0,0.0,18,18
Stochastic Value Iteration,True,True,0.3806141996383667,0.00011267142112071724,0.010614679510975226,97.0,0.0,0.0,419816.0,0.0,0.0,18,30
Discounted Stochastic Value Iteration - gamma = 0.8,True,True,0.33511526107788087,0.0010507398188418391,0.03241511713447661,83.0,0.0,0.0,359224.0,0.0,0.0,18,37
Discounted Stochastic Value Iteration - gamma = 0.6,True,True,0.29169180393218996,0.0009952966922963922,0.03154832312970678,70.0,0.0,0.0,302960.0,0.0,0.0,18,29
Random Action Value Iteration,True,False,0.11322603464126586,0.0003373940222571662,0.018368288495588428,149.0,199.0,14.106735979665885,60000.0,31840000.0,5642.694391866354,18,18
Random Action Discounted Value Iteration - gamma = 0.8,True,False,0.12250683069229126,9.838455994769788e-05,0.00991889912982776,152.0,96.0,9.797958971132712,61200.0,15360000.0,3919.183588453085,18,18
Random Action Discounted Value Iteration - gamma = 0.6,True,False,0.1332096290588379,0.0002866761560709164,0.016931513696976902,150.5,24.75,4.9749371855331,60600.0,3960000.0,1989.97487421324,18,18
Random Action Discounted Value Iteration - gamma = 0.5,True,False,0.12614277362823487,0.00012986743157400725,0.011395939258086947,150.5,24.75,4.9749371855331,60600.0,3960000.0,1989.97487421324,18,18
Random Action Discounted Value Iteration - gamma = 0.5,True,False,0.12781668901443483,0.00029690210344980985,0.017230847438527503,151.0,49.0,7.0,60800.0,7840000.0,2800.0,18,18
Q-factor Value Iteration,True,False,0.036789281368255614,4.6923915026872006e-05,0.00685010328585431,28.0,0.0,0.0,42560.0,0.0,0.0,18,18
Q-factor Stochastic Value Iteration,True,True,0.4432192635536194,0.001598950605946419,0.03998688042278891,97.0,0.0,0.0,419816.0,0.0,0.0,18,27
