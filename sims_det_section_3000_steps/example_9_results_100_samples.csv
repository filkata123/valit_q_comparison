Algorithm,Goal reached,Loops encountered,Avg Time,Var Time,STD Time,Avg Iterations,Var Iterations,STD iterations,Avg action count,Var action count,STD action count,Avg convergence action,Var convergence actio ,STD convergence action,Convergence rate,Shortest Path,Longest Path
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0",True,False,0.35912466287612915,0.0008133957045589513,0.028520092997024946,999.0,0.0,0.0,93512.0,0.0,0.0,0.0,0.0,0.0,0.0,73,73
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.25",True,False,0.4739771842956543,0.0013888098427946715,0.03726673909526659,999.0,0.0,0.0,124089.16,104105.13440000001,322.6532727247626,0.0,0.0,0.0,0.0,73,73
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.5",True,False,0.696105489730835,0.002093934606556241,0.045759530226568555,999.0,0.0,0.0,188985.0,665542.52,815.8078940534959,0.0,0.0,0.0,0.0,73,73
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.75",True,False,0.3833922910690308,0.0035250784234180854,0.05937237087583824,203.64,1544.2504000000001,39.29695153571076,108550.98,215317734.5996,14673.708958528514,108350.0,215527500.0,14680.854879740486,1.0,73,73
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.9",True,False,0.3805060839653015,0.0011918465699178513,0.03452313094025296,63.76,38.6224,6.214692269131272,104758.3,46493000.67,6818.577613402959,104150.0,46527500.0,6821.106948289258,1.0,73,73
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",True,False,2.0123833298683165,0.827928999422709,0.9099060387879119,201.71,8146.3659,90.25722076377048,598119.72,71636564107.9216,267650.07772821886,596650.0,71570027500.0,267525.75109697384,1.0,73,73
"Fully-random (deterministic with pi) exploration Q-learning (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",True,False,2.546474714279175,1.8845181111145128,1.3727775169758982,237.82,16261.327599999997,127.51991060222713,705931.0,142970807354.28,378114.80710794707,704400.0,142691640000.0,377745.469860328,1.0,73,73
Model-free Dijkstra,True,False,0.0018157482147216797,7.435803987618784e-06,0.0027268670645300597,213.0,0.0,0.0,2360.0,0.0,0.0,656.0,0.0,0.0,1.0,73,73
Model-free Value Iteration,True,False,0.026371097564697264,5.902793321865829e-05,0.0076829638303624916,56.0,0.0,0.0,38776.0,0.0,0.0,37072.0,0.0,0.0,1.0,73,73
Model-free Synchronous Value Iteration,True,False,0.033955399990081785,2.3925474480228106e-05,0.004891367342597375,74.0,0.0,0.0,50692.0,0.0,0.0,48988.0,0.0,0.0,1.0,73,73
