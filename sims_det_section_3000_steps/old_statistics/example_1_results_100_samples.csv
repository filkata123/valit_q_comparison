Algorithm,Goal reached,Loops encountered,Avg Time,Var Time,STD Time,Avg Iterations,Var Iterations,STD iterations,Avg action count,Var action count,STD action count,Avg convergence action,Var convergence actio ,STD convergence action,Convergence rate,Shortest Path,Longest Path
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0",True,False,0.17823442697525024,0.0007391232085327091,0.027186820493259396,999.0,0.0,0.0,40894.0,0.0,0.0,0.0,0.0,0.0,0.0,28,28
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.25",True,False,0.22406928539276122,0.0010387208295088613,0.032229192194482024,999.0,0.0,0.0,53343.49,46163.109899999996,214.85602132591023,0.0,0.0,0.0,0.0,28,28
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.5",True,False,0.32925862312316895,0.0022602039732852516,0.04754160255276689,999.0,0.0,0.0,79281.47,274017.4091,523.4667220559488,0.0,0.0,0.0,0.0,28,28
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.75",True,False,0.7104638624191284,0.007546184537200339,0.08686877768911186,989.68,1613.8176,40.17234869907409,173429.41,44433953.4219,6665.879793538134,160500.0,222250000.0,14908.051515875573,0.1,28,28
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.9",True,False,0.34872583150863645,0.002821762813904769,0.05312026744948456,167.39,786.0178999999999,28.036010771862674,92831.32,161297301.8376,12700.287470667741,92500.0,161750000.0,12718.097341976905,1.0,28,28
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",True,False,0.4463749122619629,0.006736466576944259,0.08207598051162264,82.85,115.6675,10.754882612097633,119999.61,305728637.29789996,17485.09757759161,119050.0,311847500.0,17659.204398839716,1.0,28,28
"Fully-random (deterministic with pi) exploration Q-learning (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",True,False,0.4059743046760559,0.004127461790041451,0.0642453250442509,80.53,106.0891,10.299956310586953,116091.02,211453316.51960003,14541.434472554625,115300.0,210410000.0,14505.51619212498,1.0,28,28
Model-free Dijkstra,True,False,0.002458620071411133,1.0467758370396039e-05,0.0032353915327817807,290.0,0.0,0.0,4015.0,0.0,0.0,1037.0,0.0,0.0,1.0,28,28
Model-free Value Iteration,True,False,0.01623459577560425,2.9146160472981818e-05,0.00539871841023236,19.0,0.0,0.0,23308.0,0.0,0.0,20330.0,0.0,0.0,1.0,28,28
Model-free Synchronous Value Iteration,True,False,0.02418086051940918,3.253742484421308e-05,0.005704158557071594,30.0,0.0,0.0,35078.0,0.0,0.0,32100.0,0.0,0.0,1.0,28,28
