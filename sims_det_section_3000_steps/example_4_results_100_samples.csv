Algorithm,Goal reached,Loops encountered,Avg Time,Var Time,STD Time,Avg Iterations,Var Iterations,STD iterations,Avg action count,Var action count,STD action count,Avg convergence action,Var convergence actio ,STD convergence action,Convergence rate,Shortest Path,Longest Path
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0",True,False,0.18543612718582153,0.000552881973060829,0.023513442390701304,999.0,0.0,0.0,46110.0,0.0,0.0,0.0,0.0,0.0,0.0,32,32
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.25",True,False,0.23485393285751344,0.0006515292752491121,0.02552507150331047,999.0,0.0,0.0,60369.82,84737.54759999999,291.0971446098364,0.0,0.0,0.0,0.0,32,32
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.5",True,False,0.34396633625030515,0.0008680336483584823,0.02946241076963123,999.0,0.0,0.0,88952.36,434129.13039999997,658.8847626102762,0.0,0.0,0.0,0.0,32,32
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.75",True,False,0.6830114555358887,0.002097608489354889,0.04579965599603221,999.0,0.0,0.0,186251.9,5238395.33,2288.754099941713,0.0,0.0,0.0,0.0,32,32
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.9",True,False,1.616561198234558,0.13816188888495903,0.37170134366848745,814.49,36817.469900000004,191.87878960427076,442570.23,9708705423.2171,98532.7631969037,386111.1111111111,6801940035.273369,82473.87486515574,0.63,32,32
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",True,False,0.9572098278999328,0.06284298156519696,0.2506850246129532,144.61,1413.9179000000001,37.602099675417065,283482.59,5282750420.301901,72682.53174114053,282300.0,5268710000.0,72585.8801696308,1.0,32,32
"Fully-random (deterministic with pi) exploration Q-learning (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",True,False,1.0005986046791078,0.07766643783164892,0.27868698898880967,145.19,1436.3738999999998,37.899523743709494,282609.81,6070401583.4939,77912.78190062205,281500.0,6071250000.0,77918.22636585102,1.0,32,32
Model-free Dijkstra,True,False,0.0025508499145507815,1.0776094073798959e-05,0.0032826961592262783,243.0,0.0,0.0,3663.0,0.0,0.0,846.0,0.0,0.0,1.0,32,32
Model-free Value Iteration,True,False,0.015757460594177247,3.364158320798652e-05,0.0058001364818413125,21.0,0.0,0.0,24447.0,0.0,0.0,21630.0,0.0,0.0,1.0,32,32
Model-free Synchronous Value Iteration,True,False,0.023443951606750488,2.4015644974269888e-06,0.0015496981955938998,34.0,0.0,0.0,37837.0,0.0,0.0,35020.0,0.0,0.0,1.0,32,32
