Algorithm,Goal reached,Loops encountered,Avg Time,Var Time,STD Time,Avg Iterations,Var Iterations,STD iterations,Avg action count,Var action count,STD action count,Avg convergence action,Var convergence actio ,STD convergence action,Convergence rate,Shortest Path,Longest Path
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0",True,False,0.17390843391418456,0.0003140563007124456,0.01772163369197224,999.0,0.0,0.0,43272.0,0.0,0.0,0.0,0.0,0.0,0.0,30,30
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.25",True,False,0.22923526287078858,0.0004245622349887755,0.020604908031553442,999.0,0.0,0.0,57033.71,66796.6859,258.45054826794234,0.0,0.0,0.0,0.0,30,30
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.5",True,False,0.32783730030059816,0.0008101153185560861,0.028462524809933606,999.0,0.0,0.0,86192.98,332056.2196,576.2431948405118,0.0,0.0,0.0,0.0,30,30
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.75",True,False,0.7033266162872315,0.0013813826799554587,0.03716695682935931,998.43,17.365100000000005,4.167145305841879,194660.71,4754400.1259,2180.458696215088,190000.0,25000000.0,5000.0,0.02,30,30
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 0.9",True,False,0.39733036041259767,0.003339067552451388,0.05778466537457311,168.45,853.6875000000001,29.217931138258233,105966.11,204849298.37789997,14312.557366798568,105600.0,204140000.0,14287.756996813741,1.0,30,30
"cost-based Q-learning true convergence (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",True,False,0.5155288934707641,0.00995643358215318,0.0997819301384433,83.54,219.90840000000003,14.829308817338724,152728.86,778207591.9604002,27896.372379942168,151550.0,775347500.0,27845.062398924518,1.0,30,30
"Fully-random (deterministic with pi) exploration Q-learning (No discounting, no stochastic approximation) w/ term action & term goal, epsilon = 1",True,False,0.5445032596588135,0.010022936492921417,0.10011461677957628,82.65,187.8075,13.704287650221007,152815.72,715714257.6616,26752.8364414243,151650.0,725527500.0,26935.61768365448,1.0,30,30
Model-free Dijkstra,True,False,0.0028717684745788574,1.3832058309907325e-05,0.0037191475246227228,282.0,0.0,0.0,3665.0,0.0,0.0,955.0,0.0,0.0,1.0,30,30
Model-free Value Iteration,True,False,0.017846009731292724,2.397809095111256e-05,0.004896742892077606,25.0,0.0,0.0,27660.0,0.0,0.0,24950.0,0.0,0.0,1.0,30,30
Model-free Synchronous Value Iteration,True,False,0.024466333389282228,1.0275860630736132e-05,0.003205598326480742,35.0,0.0,0.0,37640.0,0.0,0.0,34930.0,0.0,0.0,1.0,30,30